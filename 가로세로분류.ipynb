{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'ResNet50'\n",
    "batch_size=8\n",
    "train_data_path = './CargoContainerImages/train/'\n",
    "num_classes = 2\n",
    "max_epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 127 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode ='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == 'ResNet50':\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "    from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "    model = ResNet50(weights = None, classes=num_classes)\n",
    "    output_node_name = 'fc1000/Softmax'\n",
    "if MODEL == 'VGG16':\n",
    "    from tensorflow.keras.applications.vgg16 import VGG16\n",
    "    from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "    model = VGG16(weights = None, classes = num_classes)\n",
    "    output_node_name = 'predictions/Softmax'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 44s 3s/step - loss: 2.8833 - accuracy: 0.6772\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 43s 3s/step - loss: 1.1205 - accuracy: 0.7795\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.3510 - accuracy: 0.9213\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.3190 - accuracy: 0.8976\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.1930 - accuracy: 0.9606\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 45s 3s/step - loss: 0.1421 - accuracy: 0.9449\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 44s 3s/step - loss: 0.3784 - accuracy: 0.9370\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 44s 3s/step - loss: 0.4974 - accuracy: 0.9134\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.1854 - accuracy: 0.9685\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.4824 - accuracy: 0.9449\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit_generator(train_generator, epochs = max_epoches)\n",
    "model.save('saved_model/' + MODEL + 'saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 44s 3s/step - loss: 1.3500 - accuracy: 0.8189\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.6303 - accuracy: 0.8819\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.4506 - accuracy: 0.8898\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.6064 - accuracy: 0.8504\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 42s 3s/step - loss: 0.3943 - accuracy: 0.8819\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 41s 3s/step - loss: 0.0368 - accuracy: 0.9764\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 41s 3s/step - loss: 0.1526 - accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 41s 3s/step - loss: 0.0448 - accuracy: 0.9843\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 41s 3s/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 41s 3s/step - loss: 0.1191 - accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'VGG16'\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit_generator(train_generator, epochs = max_epoches)\n",
    "model.save('saved_model/' + MODEL + 'saved.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "#import uff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'VGG16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            4098        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if MODEL == 'ResNet50':\n",
    "    output_node_name = 'fc1000/Softmax'\n",
    "if MODEL == 'VGG16':\n",
    "    output_node_name  = 'predictions/Softmax'\n",
    "#sess = K.get_session()\n",
    "#K.set_learning_phase(0)\n",
    "#graph = tf.get_default_graph()\n",
    "model = load_model('saved_model/' + MODEL + 'saved.h5')\n",
    "model.compile(loss = 'categorical_crossenthropy', optimizer = 'adam', metrics= ['accuracy'])\n",
    "#output_graph_def = tf.graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), ['input_1', output_node_name])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uffmodel = uff.from_tensorflow(output_graph_def, [output_node_name], \n",
    "#                              output_filename = 'saved_model/' + MODEL + 'uff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "if MODEL == 'ResNet50':\n",
    "    from tensorflow.keras.applications.resnet50 import decode_predictions\n",
    "if MODEL == 'VGG16':\n",
    "    from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "def predict_all(folder):\n",
    "    HORIZONTAL = 0\n",
    "    VERTICAL = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        print(filename)\n",
    "        fullpath = os.path.join(folder, filename)  # 폴더명과 파일명을 결합\n",
    "        #print(\"fullpath\", fullpath)  \n",
    "        try:\n",
    "            # 테스트할 이미지 불러오기\n",
    "            img = load_img(fullpath, target_size=(224, 224)) \n",
    "            # ResNet에 입력하기 전에 이미지 전처리\n",
    "            x = img_to_array(img) /255.0\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            #x = preprocess_input(x)\n",
    "\n",
    "            # 이미지 분류\n",
    "            preds = model.predict(x)\n",
    "            print( preds)\n",
    "            if preds[0][0] > preds[0][1]:\n",
    "                print('HORIZONTAL')\n",
    "                HORIZONTAL += 1\n",
    "            else:\n",
    "                print('VERTICAL')\n",
    "                VERTICAL += 1\n",
    "            #print('Predicted:', decode_predictions(preds, top=1)[0])\n",
    "            print('HORIZONTAL: {}%, VERTICAL {}%'.format(HORIZONTAL/(HORIZONTAL+VERTICAL), VERTICAL/(HORIZONTAL+VERTICAL) ))\n",
    "            print(\"\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHCU2088072.jpg\n",
      "[[0.98542494 0.01457505]]\n",
      "HORIZONTAL\n",
      "HORIZONTAL: 1.0%, VERTICAL 0.0%\n",
      "\n",
      "CISU2000076.jpg\n",
      "[[2.4251055e-06 9.9999762e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.5%, VERTICAL 0.5%\n",
      "\n",
      "CKLU4111544.jpg\n",
      "[[0.92453974 0.07546028]]\n",
      "HORIZONTAL\n",
      "HORIZONTAL: 0.6666666666666666%, VERTICAL 0.3333333333333333%\n",
      "\n",
      "CPWU700522.jpg\n",
      "[[0.9876417  0.01235826]]\n",
      "HORIZONTAL\n",
      "HORIZONTAL: 0.75%, VERTICAL 0.25%\n",
      "\n",
      "FCIU3558552.jpg\n",
      "[[2.6638606e-06 9.9999738e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.6%, VERTICAL 0.4%\n",
      "\n",
      "GVTU2086449.JPG\n",
      "[[0.14847745 0.8515225 ]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.5%, VERTICAL 0.5%\n",
      "\n",
      "ICSU4925022.jpg\n",
      "[[0.9487981  0.05120191]]\n",
      "HORIZONTAL\n",
      "HORIZONTAL: 0.5714285714285714%, VERTICAL 0.42857142857142855%\n",
      "\n",
      "MWLU2480338.jpg\n",
      "[[0.98043996 0.01956008]]\n",
      "HORIZONTAL\n",
      "HORIZONTAL: 0.625%, VERTICAL 0.375%\n",
      "\n",
      "TGHU3055299.jpg\n",
      "[[9.999064e-01 9.362057e-05]]\n",
      "HORIZONTAL\n",
      "HORIZONTAL: 0.6666666666666666%, VERTICAL 0.3333333333333333%\n",
      "\n",
      "TRLU5438620.JPG\n",
      "[[0.96497536 0.03502465]]\n",
      "HORIZONTAL\n",
      "HORIZONTAL: 0.7%, VERTICAL 0.3%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_all('./CargoContainerImages/test/1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAIU8121016.jpg\n",
      "[[1.3599703e-07 9.9999988e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n",
      "CBXU2785862.jpg\n",
      "[[8.244981e-05 9.999175e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n",
      "DLSU5001789.jpg\n",
      "[[5.7178804e-09 1.0000000e+00]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n",
      "FBXU0220812.jpg\n",
      "[[1.5476744e-06 9.9999845e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n",
      "FXLU8425651.jpg\n",
      "[[3.6686881e-06 9.9999630e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n",
      "HPCU4006609.jpg\n",
      "[[9.883290e-08 9.999999e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n",
      "MTBU2033374.jpg\n",
      "[[6.6958813e-07 9.9999928e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n",
      "SCTU0017000.jpg\n",
      "[[5.3853514e-06 9.9999464e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n",
      "TCNU6120328.jpg\n",
      "[[1.4129835e-06 9.9999857e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n",
      "VICU5000230.jpg\n",
      "[[2.4059273e-07 9.9999976e-01]]\n",
      "VERTICAL\n",
      "HORIZONTAL: 0.0%, VERTICAL 1.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_all('./CargoContainerImages/test/2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5850340136054422"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 86\n",
    "b=61\n",
    "a/(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.71102676e-10 1.56775593e-09 6.33899333e-07 4.02285906e-07\n",
      "  1.18995573e-07 3.43044704e-08 1.14061187e-08 1.86256255e-09\n",
      "  1.97986072e-09 3.11168064e-10 1.82857895e-10 3.71855130e-10\n",
      "  2.36878317e-09 3.67928488e-09 3.19695798e-10 8.83174811e-10\n",
      "  3.13072803e-08 3.11225201e-09 3.42527173e-10 3.32528387e-08\n",
      "  1.96200078e-09 5.57546912e-07 2.18191012e-08 1.51773691e-07\n",
      "  3.04395904e-08 3.22587219e-08 9.52947854e-09 3.20642490e-09\n",
      "  2.90862823e-09 5.38676925e-09 4.07433504e-10 1.42372265e-08\n",
      "  8.15091727e-09 2.41507152e-08 4.86918026e-08 2.22863115e-08\n",
      "  1.41772318e-08 1.19823573e-09 1.62482561e-09 4.28137570e-09\n",
      "  4.24195301e-09 1.14656548e-10 2.69182348e-08 1.31458524e-08\n",
      "  4.61131089e-09 1.36950917e-09 1.47408766e-10 1.41981502e-08\n",
      "  8.25802760e-10 4.84810414e-09 3.96564914e-09 2.89273453e-06\n",
      "  4.81442397e-09 1.40846157e-09 1.27366040e-09 4.13008294e-10\n",
      "  1.33297648e-08 5.33506173e-09 2.46092835e-09 8.66849162e-11\n",
      "  1.01277942e-09 4.18089989e-08 1.58589213e-08 1.74744330e-10\n",
      "  6.81641132e-10 3.39403954e-08 3.57362273e-09 2.92656788e-10\n",
      "  6.98903380e-10 2.51204235e-09 3.55587648e-09 1.99613524e-07\n",
      "  1.83638562e-08 2.27925568e-07 8.62677467e-08 6.63101041e-09\n",
      "  1.23216930e-08 7.81468579e-09 9.48390266e-07 3.45887430e-09\n",
      "  9.96703609e-09 5.31747908e-08 2.17160530e-08 3.86029853e-07\n",
      "  1.07491127e-09 8.98206010e-10 1.57175677e-08 1.39904310e-08\n",
      "  2.35463427e-09 2.57114285e-09 9.26990318e-10 4.40212444e-09\n",
      "  1.25384958e-09 6.47815357e-10 1.60275686e-08 6.42872144e-10\n",
      "  6.03885608e-10 2.92952906e-09 3.17966631e-08 3.09842356e-08\n",
      "  8.90565288e-10 3.32359562e-09 2.24873720e-09 4.73941242e-09\n",
      "  6.43387343e-10 1.45244021e-08 8.65166064e-11 1.32026090e-09\n",
      "  4.89891017e-10 3.14033755e-09 4.69220662e-10 1.20441779e-09\n",
      "  3.45500553e-08 3.22996215e-07 6.94300638e-07 1.55156428e-07\n",
      "  7.05348557e-11 5.10912368e-10 4.78987019e-08 2.02150812e-08\n",
      "  2.80066654e-08 1.02672402e-07 2.52348737e-08 2.04008600e-07\n",
      "  1.46040236e-07 8.69463079e-09 7.95577506e-08 1.42914713e-09\n",
      "  1.33193112e-09 3.11019877e-09 3.73513526e-10 5.50160612e-11\n",
      "  2.22987462e-10 4.24111746e-10 8.99286423e-09 1.85816515e-10\n",
      "  2.10990267e-10 1.01094066e-08 6.37634789e-09 1.25023698e-08\n",
      "  4.90102492e-09 9.57884438e-09 2.24375007e-09 3.20856630e-09\n",
      "  9.35057358e-07 8.65151562e-10 5.33789404e-08 1.22447306e-08\n",
      "  1.28919089e-06 2.23628183e-09 2.82778938e-08 5.74891850e-08\n",
      "  1.04470921e-09 2.73534306e-10 3.36578071e-10 6.80547341e-10\n",
      "  8.33940987e-08 3.44713307e-08 5.03582021e-09 1.24138266e-09\n",
      "  1.53908175e-09 1.38545770e-08 1.21034143e-08 2.41028886e-09\n",
      "  4.92318319e-09 1.36479195e-09 4.49383836e-10 3.09576964e-09\n",
      "  1.79903936e-09 1.47370824e-10 2.50827425e-09 1.34620570e-09\n",
      "  1.06716702e-09 3.65395447e-09 2.98398328e-09 2.98527709e-08\n",
      "  1.40453682e-09 8.93038477e-10 3.10905577e-08 2.35200859e-09\n",
      "  2.40715559e-09 2.47391405e-08 1.15961303e-08 3.25845972e-09\n",
      "  9.89573667e-09 4.51384139e-08 2.84550161e-09 2.57971955e-09\n",
      "  4.21446078e-09 1.39748757e-09 2.89497382e-09 4.67772354e-09\n",
      "  2.99059844e-09 2.65984887e-08 3.28622174e-09 6.09436546e-09\n",
      "  4.86150320e-09 4.46125775e-10 4.37687397e-09 1.92224747e-09\n",
      "  5.89750648e-09 4.56351978e-09 5.62151836e-09 8.81354545e-09\n",
      "  3.73049314e-10 9.56504209e-09 3.72684683e-09 6.60563781e-09\n",
      "  3.13634629e-08 1.33851268e-08 4.39658905e-08 1.20479058e-08\n",
      "  3.12192086e-08 5.10956752e-08 5.17842969e-09 1.79182482e-08\n",
      "  3.38911654e-08 1.66277189e-07 4.51201636e-08 6.15164941e-09\n",
      "  1.39014027e-08 1.03678142e-08 3.10285153e-09 4.65744332e-09\n",
      "  1.94370098e-09 8.25536972e-09 2.26063213e-09 8.64436167e-09\n",
      "  2.06106310e-09 2.02201349e-08 7.73881181e-10 3.07054933e-08\n",
      "  1.76464408e-08 9.60439228e-11 9.99835770e-09 8.96602614e-09\n",
      "  3.54601526e-09 2.14248419e-09 6.47008136e-09 2.50231196e-08\n",
      "  3.53087071e-09 2.97224911e-08 1.27834356e-08 1.00079300e-09\n",
      "  3.33623440e-09 1.21839427e-09 2.77375989e-09 4.33388685e-08\n",
      "  4.20759534e-08 2.12188578e-09 7.47660689e-09 1.39208723e-07\n",
      "  3.08782472e-10 6.68977429e-10 2.91118663e-09 8.57614157e-09\n",
      "  2.43503013e-08 2.10998818e-09 3.04137493e-09 3.21738653e-08\n",
      "  1.63739422e-09 2.46100806e-09 3.49581031e-09 1.70927794e-09\n",
      "  3.78053748e-08 1.69209340e-08 3.81379994e-09 8.92414462e-08\n",
      "  5.04152897e-09 8.23980773e-10 8.36308744e-10 2.61718619e-10\n",
      "  1.93035987e-09 4.68827244e-09 2.16529572e-10 1.00405295e-09\n",
      "  8.48910164e-10 9.23651100e-10 7.91405136e-11 1.08595688e-09\n",
      "  7.45478790e-10 2.19388596e-09 1.45104453e-08 1.51658519e-09\n",
      "  9.07791176e-09 1.67031966e-09 3.68703845e-10 1.54338831e-09\n",
      "  6.83925000e-11 1.59237692e-10 9.94355639e-11 1.26403971e-10\n",
      "  1.40883505e-09 7.39457384e-10 1.21671588e-08 2.11972467e-10\n",
      "  4.17405310e-09 4.76421402e-11 6.25089258e-10 3.05675307e-08\n",
      "  8.27788593e-09 1.94213541e-07 4.64289975e-08 1.89086194e-07\n",
      "  1.11190694e-07 3.49193185e-09 5.87460420e-07 3.29643086e-08\n",
      "  6.56816684e-11 1.56659699e-08 1.37360656e-08 3.68201581e-05\n",
      "  1.22750789e-05 5.20864774e-07 1.45738397e-06 5.63013778e-08\n",
      "  7.61919583e-10 2.44699088e-08 6.27797059e-09 1.53762123e-08\n",
      "  2.41550335e-09 1.07922141e-07 3.48400198e-09 1.04988285e-09\n",
      "  6.16387563e-09 2.46846293e-10 6.56998083e-08 2.70151531e-07\n",
      "  3.47907623e-08 2.68721323e-07 1.81058857e-09 2.74301382e-09\n",
      "  1.99727276e-10 3.16328796e-10 1.59871383e-09 1.95129735e-09\n",
      "  1.42805989e-09 9.25381460e-09 1.55774083e-09 6.55369492e-09\n",
      "  2.03282435e-09 6.89830371e-09 2.98738145e-10 1.06771059e-09\n",
      "  5.24393062e-09 6.72326976e-08 5.80648085e-10 5.71214676e-09\n",
      "  1.40427716e-07 9.59375912e-10 2.13985114e-08 2.60451744e-10\n",
      "  7.77233167e-10 5.75320458e-09 1.94629424e-09 3.52090723e-07\n",
      "  3.70496913e-08 6.92491975e-09 1.82393667e-09 2.66266986e-09\n",
      "  3.90206267e-08 2.84858603e-09 2.07324247e-09 2.38016575e-08\n",
      "  2.99478242e-09 3.46244500e-09 9.71187991e-11 2.23974256e-10\n",
      "  1.07584928e-08 5.11647669e-10 1.00258850e-10 4.51697391e-09\n",
      "  1.64708880e-09 3.27380945e-09 1.35764433e-09 1.32857877e-10\n",
      "  2.02269890e-09 1.82259785e-09 4.55383148e-10 1.56092028e-09\n",
      "  3.12736219e-08 3.48739420e-08 2.32583086e-09 1.83497733e-07\n",
      "  1.89944043e-08 4.14649259e-10 1.38119571e-09 1.44889025e-08\n",
      "  2.95623774e-08 1.32291333e-08 1.38910050e-09 2.71612013e-08\n",
      "  1.62500846e-09 3.74019676e-10 1.82919919e-07 3.83286852e-06\n",
      "  8.66670291e-08 1.70321179e-09 2.42070003e-10 2.20077470e-10\n",
      "  5.72926373e-10 3.58550922e-09 1.94835650e-08 5.10506979e-05\n",
      "  8.37822914e-01 2.65729119e-04 2.27337482e-09 2.47419138e-07\n",
      "  3.65137147e-08 9.02697650e-09 3.88068466e-09 3.46160633e-09\n",
      "  1.58281885e-08 1.61729439e-08 7.37416883e-09 6.62482913e-09\n",
      "  1.65775820e-08 1.02075774e-07 2.38379916e-09 3.99004163e-09\n",
      "  1.13743738e-07 1.31565059e-09 8.43087111e-09 1.54217306e-09\n",
      "  2.46418191e-10 4.08953689e-08 9.11454165e-08 3.43230766e-07\n",
      "  3.94843553e-08 1.50987525e-08 5.22229104e-09 1.97460645e-10\n",
      "  5.48645629e-10 3.12455981e-08 1.36603162e-09 8.48379200e-10\n",
      "  5.36833777e-09 3.64059760e-09 7.95887856e-10 1.99853134e-09\n",
      "  5.65755585e-08 9.16416454e-09 1.26818449e-07 1.70768857e-08\n",
      "  2.17571401e-08 1.16015277e-08 2.65165179e-09 2.29442398e-09\n",
      "  4.54400606e-08 1.78423932e-07 1.33277368e-07 1.08660871e-07\n",
      "  3.21039639e-09 7.93771493e-10 1.68506176e-09 1.00360019e-07\n",
      "  8.72655050e-08 1.84939375e-09 5.26393984e-10 5.47657919e-09\n",
      "  2.93403204e-08 3.61759085e-08 5.91147433e-08 5.30176625e-10\n",
      "  1.28953745e-08 4.27229674e-09 9.93947058e-09 2.04198369e-09\n",
      "  1.32928477e-08 5.79499959e-09 3.16428966e-10 8.25474000e-09\n",
      "  6.69067433e-08 5.62720743e-06 4.53482335e-10 1.70345388e-07\n",
      "  6.12560100e-08 1.51690998e-08 9.02176023e-09 1.70696978e-07\n",
      "  8.09637601e-09 1.33771050e-09 1.14751997e-09 1.04161927e-07\n",
      "  2.31392605e-07 5.21245658e-10 9.59607879e-11 2.30589614e-09\n",
      "  1.05353379e-07 1.42922953e-08 1.93835149e-07 2.47948265e-05\n",
      "  7.95134092e-09 4.28165114e-10 1.38695935e-08 9.25479804e-10\n",
      "  1.31147226e-08 6.76578509e-08 7.78958054e-09 1.99971453e-08\n",
      "  2.61154764e-09 5.75238168e-09 5.59889735e-09 2.85946800e-09\n",
      "  1.82493629e-08 8.57882476e-09 2.82908807e-09 4.35111236e-09\n",
      "  4.64842415e-10 5.11079268e-09 2.94218605e-08 1.58466449e-08\n",
      "  1.17561979e-06 3.77209375e-09 1.64459323e-07 1.42751864e-08\n",
      "  2.08396161e-10 4.92581819e-07 1.60671458e-08 3.67068420e-09\n",
      "  4.40749104e-10 1.01297588e-10 6.66952049e-09 1.90511891e-08\n",
      "  2.78814127e-08 4.64344865e-08 7.74296449e-09 7.09415415e-10\n",
      "  1.74104259e-10 1.85612484e-10 1.64605947e-08 1.57429653e-10\n",
      "  6.71111666e-10 7.75073283e-10 6.06902806e-10 2.90741342e-09\n",
      "  3.34254828e-08 2.76966965e-08 4.63843861e-08 6.71469236e-09\n",
      "  1.57453911e-07 6.48967159e-07 2.74888112e-08 2.07735815e-10\n",
      "  6.05729911e-11 1.54048347e-08 3.37355424e-08 3.04993164e-09\n",
      "  1.86500460e-09 2.86605295e-09 5.37968226e-10 3.89783344e-10\n",
      "  8.32996250e-09 6.98692770e-10 1.38561163e-07 1.31338469e-08\n",
      "  9.57396273e-10 3.90559194e-08 1.74432649e-10 7.10970882e-09\n",
      "  8.98117403e-09 3.63215165e-08 2.02291979e-08 3.32408367e-09\n",
      "  1.43838208e-09 1.73473289e-08 5.00189223e-10 2.23265175e-08\n",
      "  9.30588329e-10 1.62412910e-08 1.95330063e-09 4.43632953e-09\n",
      "  3.68599995e-09 1.01774444e-09 1.23634791e-08 1.97066896e-08\n",
      "  1.24120980e-09 4.17613988e-09 2.85688384e-09 6.02354444e-10\n",
      "  1.49854196e-09 3.14696337e-07 1.07831450e-08 2.13169962e-08\n",
      "  1.47365000e-07 1.22226507e-09 2.72193361e-08 1.15634258e-07\n",
      "  3.37407879e-10 7.43418882e-09 1.54052660e-09 6.97107794e-09\n",
      "  3.99014066e-09 1.43677803e-09 9.74057102e-09 1.21462278e-07\n",
      "  2.85505353e-09 3.99275191e-09 3.73865072e-09 6.71437590e-08\n",
      "  7.96743720e-08 1.48280477e-09 3.74251602e-10 3.99566957e-09\n",
      "  2.48287546e-09 1.54876348e-10 5.05998410e-10 4.51690269e-10\n",
      "  5.18593213e-09 7.55237295e-08 2.46144136e-08 3.16315862e-08\n",
      "  4.29256941e-09 3.00084473e-08 1.56232616e-09 5.84354831e-09\n",
      "  1.04395887e-08 3.21297566e-09 7.13662374e-09 1.27512367e-09\n",
      "  6.61316335e-09 6.49585008e-09 3.52842688e-09 5.05835835e-08\n",
      "  3.68554104e-10 1.98428978e-07 5.90136651e-09 8.58297042e-08\n",
      "  4.66281449e-08 3.54503954e-10 2.25991101e-10 1.45467394e-09\n",
      "  2.26398056e-09 5.08474463e-09 2.28652965e-07 1.73380013e-08\n",
      "  3.57029784e-09 1.59495919e-08 1.67945693e-08 1.40127829e-08\n",
      "  1.60057093e-10 5.19670742e-08 2.13424123e-09 9.60691171e-09\n",
      "  1.47613960e-07 1.75870678e-08 3.38132833e-09 7.51270157e-09\n",
      "  1.31330136e-09 1.10600562e-09 1.28272715e-09 1.00327191e-09\n",
      "  8.29957614e-09 8.29334201e-09 1.63786371e-08 4.02777423e-10\n",
      "  4.56449740e-08 5.87861450e-06 1.07345519e-08 6.94197644e-10\n",
      "  1.72459082e-07 4.18264445e-09 1.57219766e-08 1.10595607e-07\n",
      "  3.80785448e-09 9.39322007e-08 2.49483811e-09 5.88317084e-09\n",
      "  8.55518056e-09 4.90445184e-11 9.60930890e-08 6.26989660e-08\n",
      "  1.25944866e-09 3.36013795e-09 7.24482447e-08 9.95464404e-08\n",
      "  2.45438567e-08 1.98181880e-08 1.81482052e-09 9.75892434e-09\n",
      "  4.43686243e-09 3.56620733e-09 9.00168899e-08 5.00621544e-10\n",
      "  9.49149292e-09 1.92291849e-09 2.63808531e-10 2.01407821e-10\n",
      "  2.15164087e-09 4.88341423e-10 9.80960593e-08 1.30659608e-08\n",
      "  1.72441723e-08 3.12057722e-07 2.21794494e-08 5.69674334e-08\n",
      "  7.90015875e-08 1.11282610e-08 9.33447737e-08 1.38002665e-09\n",
      "  2.08945528e-09 4.23430401e-06 7.69748931e-10 1.22674528e-08\n",
      "  1.90262944e-10 3.17243298e-08 3.45434481e-09 3.98154038e-10\n",
      "  3.39688917e-08 1.35429561e-08 1.01033925e-06 7.21263257e-11\n",
      "  2.60067679e-09 5.54818691e-10 2.50695298e-10 1.13717107e-08\n",
      "  1.76365500e-08 1.11789138e-08 1.56486109e-07 1.93882190e-08\n",
      "  3.87617938e-09 6.28265162e-10 9.55040402e-09 2.60154964e-09\n",
      "  1.20540662e-08 1.70571501e-09 6.70304479e-10 2.34953790e-09\n",
      "  4.87120067e-10 2.66545079e-08 6.23742906e-08 1.78873112e-08\n",
      "  1.11608056e-08 3.58212930e-07 1.81644566e-08 1.28050270e-09\n",
      "  3.38161210e-09 5.36599387e-09 7.67683028e-10 1.77638404e-10\n",
      "  5.04109643e-09 2.32079689e-09 1.06903109e-09 9.97389615e-10\n",
      "  7.42044404e-06 1.38888856e-09 3.67058099e-08 3.54089036e-10\n",
      "  1.25480404e-09 5.37486455e-09 4.73260764e-10 1.05553816e-07\n",
      "  9.52761141e-08 3.38287798e-08 5.62787257e-08 6.15356583e-08\n",
      "  1.01863051e-08 3.43458964e-07 6.82117829e-08 5.54575585e-09\n",
      "  1.76327486e-08 4.53114257e-09 1.20861356e-08 2.01160311e-09\n",
      "  1.81356175e-08 3.08375925e-09 1.85268079e-09 1.13069127e-08\n",
      "  1.97605896e-08 8.94150674e-08 7.25737470e-10 1.46418566e-09\n",
      "  2.53544243e-08 4.69940753e-10 2.06138573e-09 2.02524286e-09\n",
      "  5.03619502e-09 7.06023968e-08 9.08423381e-09 1.51922634e-08\n",
      "  8.53038529e-08 1.64746972e-08 8.06021383e-09 7.86437724e-08\n",
      "  4.96835861e-09 4.98646324e-09 9.78967236e-08 1.38415345e-07\n",
      "  1.82706600e-10 2.04567918e-09 4.07553241e-10 1.31303404e-08\n",
      "  4.58978882e-08 9.85267756e-10 1.03005500e-10 1.35974676e-06\n",
      "  1.45420325e-08 1.38622092e-09 2.22772045e-09 2.41686737e-09\n",
      "  7.57706675e-10 2.09120965e-09 1.69231839e-07 3.04190451e-08\n",
      "  1.34762890e-09 3.70827777e-08 1.06310232e-08 1.89717483e-07\n",
      "  2.04709039e-07 1.36584666e-09 2.36855735e-09 2.56992183e-09\n",
      "  1.10271573e-01 2.17198948e-09 3.23430811e-07 1.92034577e-07\n",
      "  1.88817069e-08 2.11047624e-08 3.17628812e-09 3.53203760e-08\n",
      "  9.33406419e-09 1.13693250e-08 2.22700365e-08 5.61935810e-11\n",
      "  2.89071989e-09 9.34516198e-09 9.35468503e-09 8.90093599e-09\n",
      "  4.44900605e-09 3.01686076e-09 3.59230645e-09 1.56448798e-09\n",
      "  4.62689869e-08 1.09079554e-06 8.96590191e-10 7.07928960e-09\n",
      "  4.60113974e-08 2.32490063e-08 7.32636263e-09 1.48247477e-08\n",
      "  6.00701533e-09 2.13220286e-09 1.44663419e-08 1.48717021e-08\n",
      "  7.11631598e-09 8.82889424e-08 5.27662580e-10 5.90641420e-08\n",
      "  5.26963850e-09 1.75346071e-09 1.60726010e-08 6.26930774e-09\n",
      "  5.82762318e-08 6.35222808e-09 1.41799354e-08 5.90682792e-09\n",
      "  2.12669946e-07 1.07910454e-08 1.02530082e-08 1.21429551e-08\n",
      "  1.16173549e-09 3.78351439e-09 8.31629876e-08 2.20067946e-07\n",
      "  1.94796357e-07 5.83976281e-08 1.73195673e-07 7.08361258e-05\n",
      "  6.41516484e-09 2.68004813e-10 1.46613424e-08 8.23892492e-07\n",
      "  5.58943576e-08 1.14607692e-08 2.59647837e-09 4.12025791e-09\n",
      "  3.56653418e-09 1.59435700e-08 2.13320339e-09 6.12982909e-09\n",
      "  1.12451444e-08 4.91135621e-09 3.55781693e-09 1.87618185e-10\n",
      "  9.95946792e-08 4.05877065e-09 5.36761857e-10 1.10055378e-08\n",
      "  1.02974823e-07 3.95345978e-09 6.39593445e-09 1.33196991e-08\n",
      "  1.65152834e-08 3.14924309e-10 2.24997709e-09 3.21559398e-03\n",
      "  9.49264778e-10 1.48420748e-10 1.76709525e-09 3.64660901e-09\n",
      "  7.01796097e-08 9.14856413e-10 6.94336699e-10 4.55102706e-10\n",
      "  1.61594382e-08 2.31548669e-09 4.60676358e-10 1.43666568e-09\n",
      "  4.81608063e-02 4.41418990e-09 6.54992061e-09 8.41915604e-09\n",
      "  4.62466652e-08 5.10036330e-07 2.78858114e-09 3.76824865e-08\n",
      "  1.42095359e-07 4.75959583e-09 4.12301704e-09 3.77270020e-08\n",
      "  3.19787419e-09 1.27180870e-08 1.68093581e-10 9.54728407e-10\n",
      "  4.55657678e-10 4.42388098e-10 2.88739560e-10 9.57485757e-10\n",
      "  5.01428365e-09 1.64601175e-07 6.88829493e-10 4.70389327e-09\n",
      "  2.35375430e-09 5.44758350e-10 6.90093260e-10 2.97438990e-10\n",
      "  7.02947145e-11 1.63000849e-10 1.21672394e-10 7.34981631e-10\n",
      "  1.50783622e-10 1.04418474e-10 3.37802591e-10 1.15434986e-08\n",
      "  3.20299565e-09 1.40464057e-10 1.02493374e-07 2.03476014e-09\n",
      "  3.45672269e-10 4.22628554e-09 6.03202988e-10 1.40656278e-10\n",
      "  8.48486004e-10 2.67444267e-09 1.81355944e-07 4.38974718e-10\n",
      "  6.96707303e-10 5.46484058e-09 2.79447818e-07 3.65788538e-10\n",
      "  4.81502971e-09 3.09423903e-10 6.51255438e-11 8.95165109e-10\n",
      "  4.62227201e-10 1.22978083e-09 8.75017503e-10 9.81701831e-10\n",
      "  1.66129066e-08 2.12747842e-09 3.28174025e-07 8.77573569e-09\n",
      "  1.77113861e-08 2.05770583e-08 3.57183727e-09 2.26343232e-07\n",
      "  1.49681441e-08 8.47083754e-07 6.56780088e-08 1.93289118e-09\n",
      "  1.12693854e-08 2.70175082e-08 3.36442807e-09 1.02295822e-07\n",
      "  4.85827059e-08 4.95541208e-09 2.02167186e-10 5.81720627e-08\n",
      "  8.94551100e-09 4.23135106e-07 1.47127954e-09 4.42727438e-10\n",
      "  3.76808140e-09 2.24812148e-11 1.91253058e-09 8.05560241e-09\n",
      "  2.00440928e-10 1.62968819e-10 2.21472796e-08 1.76109249e-09]]\n",
      "Predicted: [('n02690373', 'airliner', 0.8378229), ('n04266014', 'space_shuttle', 0.11027157), ('n04592741', 'wing', 0.048160806)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    " \n",
    "# imagenet에 미리 훈련된 ResNet50 모델 불러오기\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    " \n",
    "# 테스트할 이미지 불러오기\n",
    "img_path = 'test.jpg'\n",
    "img = load_img(img_path, target_size=(224, 224)) \n",
    " \n",
    "# ResNet에 입력하기 전에 이미지 전처리\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    " \n",
    "# 이미지 분류\n",
    "preds = model.predict(x)\n",
    "print(preds)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
